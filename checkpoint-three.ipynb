{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
   },
   "source": [
    "# Checkpoint Three: Cleaning Data\n",
    "\n",
    "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
    "\n",
    "My dataset: Dataset is from ReBrickable's database as well as a table containing the Richards' family LEGO collection. \n",
    "\n",
    "Link: https://rebrickable.com/downloads/\n",
    "\n",
    "Import the necessary libraries and create your dataframe(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_sets = pd.read_csv(\"rebrickable_sets_aarich47-2.csv\")\n",
    "colors = pd.read_csv(\"colors.csv\")\n",
    "elements = pd.read_csv(\"elements.csv\")\n",
    "inventories = pd.read_csv(\"inventories.csv\")\n",
    "inv_mf = pd.read_csv(\"inventory_minifigs.csv\")\n",
    "inv_p = pd.read_csv(\"inventory_parts.csv\")\n",
    "inv_sets = pd.read_csv(\"inventory_sets.csv\")\n",
    "mf = pd.read_csv(\"minifigs.csv\")\n",
    "part_cat = pd.read_csv(\"part_categories.csv\")\n",
    "part_rel = pd.read_csv(\"part_relationships.csv\")\n",
    "parts = pd.read_csv(\"parts.csv\")\n",
    "sets = pd.read_csv(\"sets.csv\")\n",
    "themes = pd.read_csv(\"themes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
   },
   "source": [
    "## Missing Data\n",
    "\n",
    "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set_num      0\n",
       "name         0\n",
       "year         0\n",
       "theme_id     0\n",
       "num_parts    0\n",
       "img_url      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "version    0\n",
       "set_num    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventories.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "name           0\n",
       "parent_id    141\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Themes are also used- however the parent_id null/NaN values come from sets that aren't a sub-theme.\n",
    "themes.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fig_num      0\n",
       "name         0\n",
       "num_parts    0\n",
       "img_url      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
   },
   "source": [
    "## Irregular Data\n",
    "\n",
    "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
   },
   "source": [
    "There are duplicates within the type category in the data- potentially starting as a different value, that caused some issues within the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
   },
   "source": [
    "## Unnecessary Data\n",
    "\n",
    "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c",
    "tags": []
   },
   "source": [
    "There are some data tables that I do not need to use in this set because it offers more information than I need.  The parts tables aren't going to offer what I need, as well as elements.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
   },
   "source": [
    "## Inconsistent Data\n",
    "\n",
    "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
   },
   "source": [
    "## Summarize Your Results\n",
    "\n",
    "Make note of your answers to the following questions.\n",
    "\n",
    "1. Did you find all four types of dirty data in your dataset? \n",
    "I didn't find much in the way of dirty data in this set because the database that it came from does not allow for partial entries, and is rigorously maintained. The errors that I am getting are generally coming from issues within my own record keeping, particularly smaller sets and I know that we have more minifigures. \n",
    "2. Did the process of cleaning your data give you new insights into your dataset?\n",
    "I was impressed by the lack of null values, and with how the different tables fit together, although it makes analysis slightly more difficult. There is also some variation when it comes to the differences between when a set was released and when my family acquired the set that can change some of the data as well that can't be notated in the Rebrickable data.  \n",
    "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?\n",
    "The way that the tables are set up, it can be difficult to find a way to answer questions based on my sets without making individual tables for each set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
